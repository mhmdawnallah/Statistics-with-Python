# **Statistics with Python**

# _Understanding and Visualizing Data with Python_:

## 1st Week - Intro to Data:

- Statistics:
  - **Methodological Subjec** t:
    - **Tools** and **methods** for working with and understanding data
  - Provide **insights** and also some of them are **possibly misleading**
  - Statistic vs Statistics:
    - **Statistic:**
      - Numerical or graphical summary of a collection of data
      - Ex: Average score on final exam
    - **Statistics:**
      - ðŸ”º
  - Landscape of Statistics:
    - New Application Areas === Development of new analytical methods
    - New Types of Sensors === New types of Data
    - Advances in Computing === Sophisticated analyses on Big Data
  - Statistics Metaphor:
    - **Big Tent**
    - Different Perspectives:
      - Art of Summarizing Data:
        - Data can be **overwhelming**
        - To make Data sensible involves:
          - **Reduction:**
            - Make a dataset comprehensible to human observer
          - **Summarization:**
            - Always depend primarily on goals of &quot;data consumer&quot; to be meaningful
      - Science of Uncertainty:
        - Data can be **misleading**
        - Assessing whether **claims** based on data are **meaningful**
        - Quantify **how far** our reported findings may **fall from &quot;the truth&quot;**
        - Many **Public opinion polls** reports have **Â± margin of error**
      - Science of Decisions:
        - Decision-Making = Ultimate Goal of any statistical analysis
      - Science of Variations:
        - Often focus on most typical or **Central Value**
        - Great Emphasis on understanding **Variations** in data
      - Art of Forecasting or Prediction:
        - Forecasting or Prediction = Central Tasks in Statistics
        - No Absolute Certainty
      - Science of Measurement:
        - **High Accuracy:**
          - Person&#39;s age or height
        - **More Difficult:**
          - Blood Pressure (varies minute to minute)
        - **Harder:**
          - Mood
          - Personality
      - Basis for Principled Data Collection:
        - Data often expensive and difficult to collect
  - History of Statistics Milestones:
    - Ancient Times:
      - Data Collection on Harvest Floods and Population sizes
    - 1700&#39;s:
      - Probability Theory
    - 19th Century:
      - Modern Statistics
    - 20th Century:
      - Statistical Theory Advances
      - New Application Areas, Computers
    - 21st Century:
      - Massive Data
      - Data Science
      - Machine Learning
  - Statistics and Its Allied Fields:
    - **Computer Science**
    - **Mathematics**
    - **Probability Theory**
    - **Data Science**
- Datasets:
  - NHANES:
    - **National Health and Nutrition Examination Survey**
    - They collect Cluster Samples:
      - Instead of randomly selecting individuals from all over the nation, There is a Random selection of geographic areas, and invited to take part in the main survey
      - Sampling Geographical areas
- Advices for Beginner Researchers:
  - Don&#39;t be shamed to get help at the very beginning of research
  - What impact of research on society?
- Quotes:
  - &quot; **You&#39;re never going to really learn statistics until you sit down and dot it&quot;**
- Data:
  - Numbers
  - Images:
    - **Eigenfaces** :
      - Represent your faces in numbers
    - **Facial Recognition**
    - Examples:
      - Quick Draw With Google
  - Words:
    - Harry Potter New Chapter Generator
    - Electronic health record (EHR)
    - Document Classification
  - Audio:
    - Audio Identification Place
    - Adobe Suite Applications to do some voice editing
    - Voice Replication Apps
  - Historical Example:
    - Florence Nightingale:
      - Founder of Nursing
      - One of the big founders of statistics:
        - Collecting a lot of information on the patients
        - And Understanding what all of this data has contained
        - Create Coxcomb Chart (Similar to Pie Chart)
        - Make Data Visualizations to Data
  - Types of Data:
    - Organic / Process Data:
      - Generated by Computerized Information System over time
      - Extracted from Video or Audio Recordings
      - **Examples:**
        - Financial or Point of sale transactions / Stock market exchanges
        - Netflix Viewing History
        - Web Browser Activity
        - Sporting Events
        - Temperature / Pollution / Fluctuations Sensors
      - These processes generate massive quantities of data called **Big Data**
      - **Data Scientists**** mine **these data to study** trends **and uncover** interesting relationships**
    - &quot;Designed&quot; Data Collection:
      - Designed to specifically address a stated research objective
      - **Examples:**
        - Individuals samples from a population, interviewed about opinions on a particular topic
      - **Common Features of Designed Data:**
        - **Sampling from Populations** , Administration of carefully designed questions
        - These **data sets** much **smaller** compared to organic / process data sets
        - Data Collected for **very specific reasons** , rather than simple reflections of ongoing natural process
    - **Question needs to be asked on Both Cases Either it is Designed Data or Organic Data?**
      - Can the data be considered i.i.d Data?
        - &quot;I&quot; refer to **Independent:**
          - Observations on a variable of interest in i.i.d case are completely independent of all observations
          - There&#39;s no correlation between the different measurements collected from different units in the population
        - &quot;Id&quot; refers to **Identically distributed**
        - **Example for this question and its answer:**
          - Final Exam Scores:
            - Independent Observations:
              - Each Student has Its unique score in exam
            - Common Statistical Distribution:
              - In this example it follows Common Normal Distribution - Bell Shape Curve
      - Not i.i.d Data:
        - Males and Females have different means:
          - So it is different Distributions
        - Students sitting next to each other tend to have similar scores:
          - Not Independent
        - **Solution:**
          - Dependencies and differences need to be accounted for in analysis:
            - **Need different analytic procedures**
      - _ **ALWAYS CONSIDER WHERE DATA CAME FROM ON WHICH Applied Analytics Procedures DEPENDING** _
- **Variable Types:**
  - Quantitative Variables:
    - **Numerical** , **Measurable** Quantities in which **arithmetic** operations often **make sense**
    - Types:
      - Continuous:
        - Any value within an interval
        - Examples:
          - Height
          - Weight
          - Time
      - Discrete:
        - Countable value, finite number of values
        - Examples:
          - Number of Children in a household
  - Categorical (or Qualitative) Variables:
    - **Classifies** individuals or items into different **groups**
    - Types:
      - Ordinal:
        - Order or Ranking associated with it
        - Examples:
          - Ranking student in College:
            - Freshman
            - Sophomore
            - Junior
            - Senior
      - Nominal:
        - Named only, no ranking
        - Examples:
          - Races
          - Marital Status
- Study Design in Various Fields
- **Types of Research Studies:**
  - Exploratory vs Confirmatory:
    - Confirmatory:
      - We have **hypothesis** , then **test** it
      - Collect data to address single pre-specified question
    - Exploratory:
      - Collect and analyze data **without first pre-specifying question**
  - Comparative vs Non-Comparative:
    - Comparative Research Studies:
      - Many other research studies are **compared to the nature**
      - **Goal = contrast** one quantity to another
    - Non-Comparative Research Studies:
      - **Focus** = **estimating or predicting** absolute quantities not (explicitly) comparative
  - Observational vs Experiments:
    - Observational Research Study:
      - bserves individuals and measures variables of interest but does **not attempt to influence** the response.
      - Subjects are **&quot;Exposed&quot;** to a condition rather than being assigned
    - Experiment Research Study:
      - **Treatment (Influence on Responses)** + Observation
      - Often involve a **Random Assignments** of subjects to &quot;treatment arms&quot;
      - **Purpose** :
        - Determine whether the treatment causes a change in the response
- Hypothesis Testing:
  - We start Hypothesis Testing before Sampling and Data will either support or refute the hypothesis statement
  - Then we make conclusion whether or not data supports the claim
- Power and Bias:
  - **Power Analysis:**
    - **Process** to **assess** whether given **study** design **likely** to **yield**** meaningful findings**
  - **Bias:**
    - Measurements that are systematically off-target or sample are not representative of a population of interest
    - **Observational Studies** are a little more **vulnerable** to it
- Data Management &amp; Manipulation:
  - **Data Management:**
    - refers to all **steps** of **data processing** that occur after the data are collected but **before** the actual **data analysis.**
    - Structure:
      - **Rows** represent **cases, observations**
      - **Columns** represent **variables**
    -
### Best Practices for Data Management:

      - Never modify the source data files (you want to preserve a record of the data as you received it).
      - Write a script (e.g. a Python program) to generate your analysis files from the source data files
      - Name variables with brief interpretable names, underscore character (\_) will be handled easily by most statistical software.
      - Most statistical software will treat **blank** , &quot; **NA**&quot;, or &quot; **.**&quot; as **a missing value**
- Spreadsheet Software:
  - Spreadsheet software can be useful for getting **a quick overview** of a data set, but is quite **limited** for more **advanced data management and analysis.**
  - **Font style and text color** in a spreadsheet are generally **not interpretable** by statistical software so should not be used to encode important information as well as **Graphs and Charts**
  - Each **sheet** in a spreadsheet **workbook** is usually imported as a **separate dataset**.
  - **Python** can read most **Excel files** directly, but may **struggle** with **large** , **complex** , or very **old** files.
  - **Text/CSV** is a **better** choice than spreadsheet formats (e.g. . **xlsx** ) for **data exchange and archiving**.
- Databases and Other Tools:
  - HDF5, Apache Parquet, and Apache Arrow are open-source standards for large binary datasets. Using these formats saves processing time relative to text/csv because fewer conversions are performed when reading and writing the data.
  - **Hadoop and Spark** are two popular tools for manipulating **very large datasets.**
- Data Files for Storage and Exchange:
  - **Text/CSV** is currently the most **universal format** for **data exchange**.
  - The data in a **CSV** file is &quot; **delimited**&quot;, usually by a **comma** or a **tab**.
  - Large data sets can be saved in compressed form (e.g. using &quot;gzip&quot;) and read into statistical software directly from the compressed file. This allows the data to be read much faster, and reduces storage space.
  - Formats like **XML** and **JSON** are useful for **non-rectangular data** but tend to produce larger files that are **slower** to read and process.
- Repeated Measures Data: Wide and Long:
  - &quot;Repeated measures&quot; arise when multiple measurements are made on each subject in a study.
  - Common Formats:
    - **Wide Format:**
      - One **Row** per **Subject**
    - **Long Format:K**
      - One **Row** per **measurement**
  - Python/Pandas has tools to convert between wide and long form.
- **Jupyter Notebook:**
  - Jupyter is **a web-based interactive** development environment that supports multiple programming languages,
  - Features:
    - File Browser
    - Markdown Cells &amp; Syntax
    - Kernels, Variables, &amp; Environment
    - Command vs. Edit Mode &amp; Shortcuts
  - Markdown:
    - Markdown is a markup language that uses plain text formatting syntax. This means that we can modify the formatting our text with the use of various symbols on our keyboard as indicators.
    - Text modifications:
    - Emphasis, aka italics, with _asterisks_ or _underscores_.
    - Strong emphasis, aka bold, with **asterisks** or **underscores**.
    - Combined emphasis with **asterisks and** _ **underscores** _.
    - Strikethrough uses two tildes. ~~Scratch this.~~
  - Kernels,Environment:
    - A Notebook Kernel:
      - a &quot; **computational engine**&quot; that executes the code contained in a Notebook document. There are **kernels** for various **programming languages** , however we are solely using the python kernel which executes python code.
      - When a notebook is **opened** , the associated **kernel** is automatically **launched** for our convenience.
      - Back-end of our notebook:
        - Execute Python code
        - Stores our initialized variables
      - A cell still being executing is indicated by the [\*] on the left-hand side of the cell.
      - When we restart our Kernel All Variables will be lost
  - Command vs Edit Mode vs Shortcuts:
    - Command Mode:
      - Blue = Command Mode
      - Green = Edit Mode
      - Triggered by pressing **Esc**
- Pandas:
  - Data Structures:
    - Two-Dimensional Table (**Data Frame)**
    - One-Dimensional Table ( **Series** )
  - Functions:
    - Pandas has a variety of functions named &#39;read\_xxx&#39; for reading data in different formats
    - Pandas has functions called isnull and notnull that can be used to identify where the missing and non-missing values are located in a data frame. Below we use these functions to count the number of missing and non-missing DMDEDUC2 values.